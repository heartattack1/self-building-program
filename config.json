{
  "llm": {
    "mode": "inference4j",
    "timeout_ms": 120000,
    "max_output_chars": 32000,
    "seed": null,
    "temperature": 0.0,
    "max_tokens": 768,
    "top_p": 1.0,
    "inference4j": {
      "model_path": "/home/roberts31337/dev/local/self-building-program/models/Meta-Llama-3-8B-Instruct.Q8_0.gguf",
      "context_length": 2048
    }
  }
}